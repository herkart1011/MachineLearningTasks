{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "|      | Hidden_Layers   | Activation   |   Epochs |   Learning_Rate |   Batch_Size |        Loss |   Accuracy |   MAE |   MSE |       R2 |\n",
      "+======+=================+==============+==========+=================+==============+=============+============+=======+=======+==========+\n",
      "| 4917 | [4, 16]         | ReLU         |      100 |           0.01  |          128 | 0.0425412   |      0.9   | 0.1   | 0.1   | 0.59803  |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 8126 | [16, 32, 64]    | Sigmoid      |       50 |           0.001 |           64 | 0.174808    |      0.895 | 0.105 | 0.105 | 0.577932 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 5102 | [4, 16]         | Tanh         |       50 |           0.001 |           64 | 0.175496    |      0.895 | 0.105 | 0.105 | 0.577932 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 5966 | [16, 32]        | Tanh         |       50 |           0.001 |           64 | 0.157296    |      0.89  | 0.11  | 0.11  | 0.557833 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 4886 | [4, 16]         | ReLU         |       50 |           0.001 |           64 | 0.168844    |      0.89  | 0.11  | 0.11  | 0.557833 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 4706 | [4, 16]         | Sigmoid      |      100 |           0.001 |           64 | 0.184997    |      0.89  | 0.11  | 0.11  | 0.557833 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 4592 | [4, 16]         | Sigmoid      |       10 |           0.01  |           64 | 0.177109    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 3720 | [64]            | Sigmoid      |       10 |           0.1   |           16 | 0.066058    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 7393 | [4, 16, 32]     | ReLU         |       10 |           0.1   |           32 | 0.175292    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 5714 | [16, 32]        | ReLU         |       25 |           0.001 |           64 | 0.160902    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 4705 | [4, 16]         | Sigmoid      |      100 |           0.001 |           32 | 0.19004     |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 7731 | [4, 16, 32]     | Tanh         |      100 |           0.001 |          128 | 0.151736    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 4628 | [4, 16]         | Sigmoid      |       25 |           0.01  |           64 | 0.158222    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 1209 | [8]             | Sigmoid      |       50 |           0.01  |          128 | 0.145966    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 4591 | [4, 16]         | Sigmoid      |       10 |           0.01  |           32 | 0.197704    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "|  422 | [4]             | Sigmoid      |      250 |           0.001 |           64 | 0.176168    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "|  421 | [4]             | Sigmoid      |      250 |           0.001 |           32 | 0.189024    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 6795 | [32, 64]        | Tanh         |       25 |           0.001 |          128 | 0.158789    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "|  384 | [4]             | Sigmoid      |      100 |           0.001 |           16 | 0.292805    |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n",
      "| 4262 | [64]            | Tanh         |      100 |           0.1   |           64 | 2.36141e-05 |      0.885 | 0.115 | 0.115 | 0.537735 |\n",
      "+------+-----------------+--------------+----------+-----------------+--------------+-------------+------------+-------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Generate dummy data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define MLP model class\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, activation_fn):\n",
    "        super(MLPModel, self).__init__()\n",
    "        layers = []\n",
    "        for neurons in hidden_layers:\n",
    "            layers.append(nn.Linear(input_size, neurons))\n",
    "            layers.append(activation_fn())\n",
    "            input_size = neurons\n",
    "        layers.append(nn.Linear(input_size, 1))  # Output layer\n",
    "        layers.append(nn.Sigmoid())  # Sigmoid for binary classification\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define hyperparameters\n",
    "hidden_layer_options = [[4], [8], [16], [32], [64], [4, 16], [16, 32], [32, 64], [4, 16, 32], [16, 32, 64]]\n",
    "activation_functions = [nn.Identity, nn.Sigmoid, nn.ReLU, nn.Tanh]\n",
    "epoch_options = [1, 10, 25, 50, 100, 250]\n",
    "learning_rate_options = [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
    "batch_size_options = [16, 32, 64, 128, 256, 512]\n",
    "\n",
    "# Train and evaluate model for each combination\n",
    "results = []\n",
    "\n",
    "for hidden_layers in hidden_layer_options:\n",
    "    for activation_fn in activation_functions:\n",
    "        for epochs in epoch_options:\n",
    "            for lr in learning_rate_options:\n",
    "                for batch_size in batch_size_options:\n",
    "                    # Initialize model, loss function, and optimizer\n",
    "                    model = MLPModel(X_train.shape[1], hidden_layers, activation_fn)\n",
    "                    criterion = nn.BCELoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                    # Training loop\n",
    "                    model.train()\n",
    "                    for epoch in range(epochs):\n",
    "                        for i in range(0, len(X_train_tensor), batch_size):\n",
    "                            X_batch = X_train_tensor[i:i+batch_size]\n",
    "                            y_batch = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "                            outputs = model(X_batch)\n",
    "                            loss = criterion(outputs, y_batch)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # Evaluate the model\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        predictions = model(X_test_tensor).round()\n",
    "                        accuracy = accuracy_score(y_test, predictions.numpy())\n",
    "                        mae = mean_absolute_error(y_test, predictions.numpy())\n",
    "                        mse = mean_squared_error(y_test, predictions.numpy())\n",
    "                        r2 = r2_score(y_test, predictions.numpy())\n",
    "\n",
    "                    # Store the results\n",
    "                    results.append({\n",
    "                        'Hidden_Layers': hidden_layers,\n",
    "                        'Activation': activation_fn.__name__,\n",
    "                        'Epochs': epochs,\n",
    "                        'Learning_Rate': lr,\n",
    "                        'Batch_Size': batch_size,\n",
    "                        'Loss': loss.item(),\n",
    "                        'Accuracy': accuracy,\n",
    "                        'MAE': mae,\n",
    "                        'MSE': mse,\n",
    "                        'R2': r2\n",
    "                    })\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "results_df.to_csv('MLP_Dummy_Classification_Results.csv', index=False)\n",
    "\n",
    "# Print top 20 results in tabulated format\n",
    "print(tabulate(results_df.head(20), headers='keys', tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Generate predictions on the test set\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Generate predictions on the test set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).round().numpy()\n",
    "    y_true = y_test.values\n",
    "\n",
    "# Create the classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
